# Agentic-AI Tutorial

This comprehensive tutorial explains the internal details of the Agentic-AI framework, focusing on the Green & White agent architecture, evaluation metrics, routing logic, and platform integration.

## 1. Green & White Agents Implementation

The framework uses a color-coded agent system to separate responsibilities:

### Green Agent (The Environment)
*   **Role**: Acts as the **Environment and Evaluator**. It simulates the world, generates requests, manages the vehicle fleet, and judges the performance of the White Agent.
*   **Core Implementation**: `src/environment/green_agent_environment.py`
    *   **`GreenAgentEnvironment`**: The main class that orchestrates the simulation.
    *   It holds the `RequestSimulator`, `VehicleSimulator`, and `Evaluator`.
    *   It exposes `run_evaluation()` which feeds requests to the White Agent one by one.

### White Agent (The Solver)
*   **Role**: Acts as the **Solver**. It receives natural language requests, parses them, and makes routing decisions (assigning vehicles).
*   **Core Implementation**: `src/white_agent/`
    *   **`WhiteAgentBase`** (`src/white_agent/base_agent.py`): The abstract base class defining the interface.
    *   **`BaselineAgents`** (`src/white_agent/baseline_agents.py`): Example implementations like `RegexBaselineAgent` (rule-based) and `RandomBaselineAgent`.
    *   **Key Methods**:
        *   `parse_request(nl_request, vehicle_db)`: Converts text to structured data.
        *   `make_routing_decision(structured_request, vehicle_db)`: Assigns a vehicle to the request.

---

## 2. Green Agent / Evaluation Details

The Green Agent evaluates the White Agent's performance using specific metrics and data flows.

### Revenue per Mile Computation
The **Revenue per Mile** is a key efficiency metric calculated in `src/evaluation/evaluator.py`.

*   **Formula**:
    $$ \text{Revenue per Mile} = \frac{\text{Total Revenue}}{\text{Total Trip Miles} + \text{Total Deadhead Miles}} $$
*   **Components**:
    *   **Total Revenue**: Sum of fares from all completed trips.
    *   **Total Trip Miles**: Miles driven with a passenger.
    *   **Total Deadhead Miles**: Miles driven empty (to pickup locations).
*   **Code Reference**: `RoutingMetrics.revenue_per_mile` in `src/evaluation/evaluator.py`.

### Score Computation
The **Overall Score** is a weighted combination of parsing accuracy and routing efficiency, calculated in `Evaluator._calculate_overall_score`.

*   **Formula**:
    $$ \text{Score} = (0.3 \times \text{Parsing Score}) + (0.7 \times \text{Routing Score}) $$
*   **Components**:
    *   **Parsing Score**: Average accuracy of identifying origin zone, destination zone, time constraints, and special requirements (0-100).
    *   **Routing Score**: Normalized Net Revenue (Net Revenue / 10.0, capped at 100).
    *   **Net Revenue**: `Total Revenue - (Deadhead Miles * Idle Cost per Mile)`.

### Log Saving
Evaluation logs are saved using the `EventLogger` and JSON serialization.

*   **Mechanism**: The `GreenAgentEnvironment` uses `self.logger` (an instance of `EventLogger`) to record events like `log_request_arrival`, `log_routing_decision`, etc.
*   **Storage**: Results are saved to a JSON file via `save_results()` method in `GreenAgentEnvironment`.
*   **Structure**: The output JSON contains the full `evaluation_summary`, `processed_requests` (with success/fail status), and fleet statistics.

### Data Generation
Data is generated by the `RequestSimulator` (`src/request_simulation/request_simulator.py`).

1.  **Load Data**: Reads NYC trip data (Parquet format) using `NYCTripDataPreprocessor`.
2.  **Contextualize**: Adds Point-of-Interest (POI) data and Customer Profiles (`CustomerProfileDatabase`).
3.  **Generate Requests**:
    *   **Template-based**: Fills pre-defined templates with trip details.
    *   **LLM-based**: Uses an LLM (OpenAI/Anthropic) to generate realistic natural language variations.
4.  **Augment**: Optionally uses Google Maps API (`LocationAugmenter`) to get precise coordinates and addresses for zone-based data.

---

## 3. White Agent Detail: Routing Decision

The routing decision logic is encapsulated in the `make_routing_decision` method of the White Agent.

### How Routing is Decided
1.  **Input**:
    *   `structured_request`: The parsed request containing origin, destination, time constraints, etc.
    *   `vehicle_database`: Access to the current state of the fleet (locations, availability).
2.  **Logic (Baseline)**:
    *   The `RegexBaselineAgent` (and `DummyWhiteAgent`) typically searches for **available vehicles** (`get_available_vehicles`).
    *   It selects a vehicle based on simple heuristics, such as the **nearest available vehicle** to the origin.
3.  **Output**:
    *   Returns a `RoutingDecision` object containing:
        *   `vehicle_id`: The ID of the assigned vehicle.
        *   `estimated_pickup_distance_miles`: Estimated distance to pickup.
        *   `decision_rationale`: A string explaining why this vehicle was chosen.

---

## 4. Front-end Detail & Orchestration

### Evaluation Orchestration
The AgentBeats platform orchestrates evaluation via a centralized "Battle" system managed by the backend (`src/backend/routes/battles.py`).

1.  **Battle Creation**: A user (via Frontend) creates a "Battle" specifying the **Green Agent** (Environment) and **Opponent(s)** (White Agents).
2.  **Queue & Lock**: The battle is queued. A background processor picks it up and **locks** the participating agents to prevent concurrent usage.
3.  **Reset & Init**: The backend sends a `reset` signal to the agents' **Launchers** (sidecar servers managing the agent processes) to ensure a clean state.
4.  **Handshake**: The backend notifies the Green Agent about the participating White Agents (URLs, names).
5.  **Execution**: The Green Agent starts the simulation, sending HTTP requests to the White Agents' endpoints.
6.  **Result Reporting**: The Green Agent posts the final results back to the backend (`/battles/{id}`), which updates the database and broadcasts the result via WebSockets to the frontend.

### Setup Instructions (AgentBeats-v2)

To set up the agents on the AgentBeats-v2 platform, follow these steps.

**Note**: `run_ctrl` in your template likely refers to the `run` command which starts the Agent Controller (Launcher).

```bash
# 1. Setup basic dependencies
sudo apt-get upgrade
sudo apt-get install build-essential git

# 2. Setup Python environment (using uv for speed)
curl -LsSf https://astral.sh/uv/install.sh | sh
source $HOME/.local/bin/env

# 3. Setup Workspace
# Clone this repository (assuming you are working with Agentic-AI)
# If using the example repo from your template:
# git clone https://github.com/agentbeats/agentify-example-tau-bench.git
# cd agentify-example-tau-bench/
# git checkout 78b1201

# For Agentic-AI repo:
# git clone <your-repo-url>
# cd Agentic-AI
uv sync
source .venv/bin/activate

# 4. Run the Agent with Controller
# This starts the Agent Controller (Launcher) which manages the agent process.
# Replace values with your specific configuration.

# Example for a Green Agent:
HTTPS_ENABLED=true \
CLOUDRUN_HOST=tutorial.agentbeats.org \
ROLE=green \
agentbeats run agent_card.toml --agent_port 8001 --launcher_port 8000

# Explanation of flags:
# run: Starts the agent launcher (controller)
# agent_card.toml: Configuration file for the agent
# --agent_port: Port where the actual agent logic runs
# --launcher_port: Port where the controller listens for reset signals
```

**Verification**:
You should see output indicating the server is running, for example:
> `Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)`

This sets up the agent to be discoverable and controllable by the AgentBeats backend for battles.
